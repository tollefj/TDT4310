{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Topic Modeling and Named Entity Recognition\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Topic Analysis and Unsupervised vs Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the difference between supervised and unsupervised learning? Discuss some benefits and issues for each approach in the context of topic analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. You are presented with a large dataset of news articles where only 50% of the data has labeled topics (finance, sports, politics, etc.). You want to assign labels to the remaining data. Explain which approach you would take (no programming!)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Could the previous question be improved by incorporating ideas from semi-supervised learning? Explain.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Metrics are essential when dealing with machine learning. However, regarding unsupervised clustering (e.g., of topics), we cannot use the typical precision, recall, and f-measure metrics. What are the alternatives for this task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the five sentences:\n",
    "\n",
    ">\"Macrosoft announces a new Something Pro laptop with a detachable keyboard.\"\n",
    "\n",
    ">\"Melon Tusk unveils plans for a new spacecraft that could take humans to Mars.\"\n",
    "\n",
    ">\"The top-grossing movie of the year Ramvel Retaliators.\"\n",
    "\n",
    ">\"Geeglo releases a new version of its Cyborg operating system.\"\n",
    "\n",
    ">\"Fletnix announces a new series from the creators of Thinger Strangs.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. How would *you* (without programming) assign the listed sentences to separate topics? Consider techniques we have discussed in the course so far (especially Lab 4)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two well-established algorithms for topic discovery are Latent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "**2. What preprocessing steps should we consider before implementing these algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Both LSI and LDA require the user to specify the number of topic clusters. How can we attempt to *automatically* detect a reasonable number of topics?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise - Topic Analysis and Modeling of Product Reviews\n",
    "We will now be using an Amazon product review dataset to perform topic modeling. The dataset specifically contains reviews of \"appliances\", a subset (~100k reviews, ~50 MB) of the full product review corpus (<https://www.kaggle.com/datasets/cynthiarempel/amazon-us-customer-reviews-dataset> - 55GB!)\n",
    "\n",
    "This task is somewhat open, and whether you want to just cluster isolated reviews, or within subsets from the review score, is up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the dataset with `pandas`, apply some preprocessing steps you find suitable, and use at least five different techniques to visualize the data, based on what you have learned in the course.**\n",
    "- Hint: look up exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO visualize the reviews in at least five different ways\n",
    "# must include some of the techniques used in this course.\n",
    "# this can be plots, graphs, trees, lists, other statistics, ...\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"amazon_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Before implementing off-the-shelf topic models, it is useful to consider how to process data for topic analysis. Consider what you have learned so far to generate a processing function and discuss your findings. This should only operate on a word level!**\n",
    "\n",
    "Below is a snippet to fetch some examples from the review corpus. You can use these to test your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[\"review_body\"].sample(frac=1).tolist()\n",
    "for review in reviews[:5]:\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: a preprocessing function to gather words/groups of words/chunks that you consider important for topic analysis/modeling\n",
    "from typing import List\n",
    "\n",
    "def preprocess_for_topic(document: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocesses a document\n",
    "    Args:\n",
    "        document (str): The input document to be preprocessed.\n",
    "    Returns:\n",
    "        List[str]: A list of words obtained by splitting the document.\n",
    "\n",
    "    Example:\n",
    "        input: \"This is a test.\"\n",
    "        output: [\"This\", \"is\", \"a\", \"test.\"]\n",
    "    \"\"\"\n",
    "    return document.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**3. Using the same data, implement a topic model with LDA using the Gensim library. Experiment with different topic counts (e.g., 3) and retrieve the top 5 words from each. Discuss your findings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LDA topic model using Gensim (and NLTK/SpaCy/scikit-learn if preferred for processing)\n",
    "# should use earlier preprocessing ideas from the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**4. With the LDA model you trained above, perform topic prediction on a sample from the test dataset, and do a simple empirical evaluation of the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_df = pd.read_csv(\"amazon_test.csv\")\n",
    "test_reviews = test_df[\"review_body\"].tolist()\n",
    "\n",
    "# some reviews are looong. let's filter out some on length.\n",
    "test_reviews = [review for review in test_reviews if len(str(review).split()) < 30]\n",
    "test_reviews = random.sample(population=test_reviews, k=10)\n",
    "test_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predict topics.\n",
    "# input: 10 random samples from `amazon_test.csv`\n",
    "# output: print the review, predicted topic, which words are contained within the predicted topic, along with the confidence score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, you learned about noun phrases. Noun phrases such as \"The slow white fox\", a person \"Name Nameson\", a place \"Mount Doom\" or company names \"NTNU\", are some examples of what we consider *named entities*.\n",
    "\n",
    "\n",
    "**1. Can you think of named entity categories that are *not* noun phrases?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disambiguating (or entity linking) named entities is a crucial task to applications of NER and considers the problem of assigning an identifier to each entity, i.e., linking relevant entities together. The disambiguation process often incorporates external knowledge (knowledge bases).\n",
    "\n",
    "\n",
    "Consider the sentences:\n",
    "\n",
    "- \"I ate an apple in New York\"\n",
    "- \"New York Times wrote an article about Apple\"\n",
    "- \"New York is also known as the Big Apple\"\n",
    "\n",
    "**2. How would you tackle the task of distinguishing the entities found here? Describe your approach either in text or by code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Load the reviews dataset, and extract named entities and their category from 100 reviews. Visualize the named entity categories and their frequencies.**\n",
    "\n",
    "- For visualization, you can use tables or plots (e.g. `matplotlib` or `seaborn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: group entity categories and visualize by frequency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
