{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "pos_reviews = movie_reviews.sents(categories=['pos'])\n",
    "neg_reviews = movie_reviews.sents(categories=['neg'])\n",
    "\n",
    "def review_filter(review):\n",
    "    return len(review) > 10\n",
    "\n",
    "pos_reviews = [review for review in pos_reviews if review_filter(review)]\n",
    "neg_reviews = [review for review in neg_reviews if review_filter(review)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the \"sents\" and \"raw\" access to a corpus in nltk typically returns whitespace tokenized sentences.\n",
    "\n",
    "To reflect a more realistic scenario, we will detokenize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: films adapted from comic books have had plenty of success , whether they ' re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there ' s never really been a comic book like from hell before .\n",
      "detokenized: films adapted from comic books have had plenty of success, whether they're about superheroes (batman, superman, spawn), or geared toward kids (casper) or the arthouse crowd (ghost world), but there's never really been a comic book like from hell before.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "twd = TreebankWordDetokenizer()\n",
    "\n",
    "def detokenize(review):\n",
    "    detokenized = twd.detokenize(review)\n",
    "    # treebankworddetokenizer doesn't work with \"there's\" or \"don't\". It will return \"there 's\" etc.\n",
    "    detokenized = re.sub(r\"'\\s([a-z])\", r\"'\\1\", detokenized)  # remove spaces around apostrophes\n",
    "    detokenized = re.sub(r\"\\s([.,?!:;])\", r\"\\1\", detokenized)  # remove spaces before punctuation\n",
    "    detokenized = detokenized.replace('\"', '')  # get rid of quotes\n",
    "    detokenized = re.sub(r\"\\s+\", r\" \", detokenized)  # multiple spaces to single space\n",
    "    return detokenized\n",
    "\n",
    "print(\"normal:\", \" \".join(pos_reviews[0]))\n",
    "print(\"detokenized:\", detokenize(pos_reviews[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29f1e52c0d8d5e5ede6aaca4be8238d35b46afd62a3b8286547e2768de775769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
