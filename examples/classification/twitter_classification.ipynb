{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faec64f9-7525-4911-96b8-23a6846bc403",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Practice - Twitter classifier\n",
    "With the Tweet Corpus from two Twitter accounts (archives from Ariana Grande and Trump)\n",
    "\n",
    "2) \n",
    "3) Set up and fit a linear model and predict which account an input tweet is from and its probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03887a9-6f2a-41f4-9389-b13bb3544b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff326d4-30df-49ae-bb6c-379be4a47d6a",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "You may find these useful in the lab. Feel free to modify for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b872392-ee78-41f3-b2d6-6cdf776a084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(data, probs, label1, label2, n=10):\n",
    "    percent = lambda x: \"{}%\".format(round(x*100, 1))\n",
    "    \n",
    "    for text, pred in list(zip(data, probs))[:n]:\n",
    "        print(\"{}\\n{}: {} / {}: {}\\n{}\".format(\n",
    "            text,\n",
    "            label1,\n",
    "            percent(pred[0]),\n",
    "            label2,\n",
    "            percent(pred[1]),\n",
    "            \"-\"*50  # to print a line\n",
    "        ))\n",
    "        \n",
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data)\n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44c2e7-c49d-4470-90a6-f5493fb19860",
   "metadata": {},
   "source": [
    "### Cleaning function\n",
    "Create a simple text cleaning function, as tweets are sensitive to major reformatting. You may experiment with this statement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32521d28-e16a-415c-b50b-a8224d956f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_text_clean(text):\n",
    "    tokens =  TweetTokenizer().tokenize(str(text).lower())\n",
    "    stop = stopwords.words(\"english\")\n",
    "    tokens = [w for w in tokens if w.isalpha() and w.lower() not in stop and w.lower() != \"rt\"]\n",
    "    return \" \".join(tokens).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0751a34-9e92-420e-8a8e-f60f2a2513b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch data from /twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa0d488-c24e-4bce-a500-96e5384a1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(name, test_size=0.1):\n",
    "    with open(\"twitter_data/{}.json\".format(name), encoding=\"utf-8\") as f:\n",
    "        tweets = [t.get(\"text\") for t in json.load(f)]\n",
    "        cleaned = [twitter_text_clean(t) for t in tweets]\n",
    "        \n",
    "        return train_test_split(cleaned, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a930c26-3f85-41eb-a0c0-bf3f68523dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 320\n"
     ]
    }
   ],
   "source": [
    "# TODO: experiment with this parameter!\n",
    "\"\"\"\n",
    "initially gather a train and test set of each tweet file.\n",
    "below, we use train to create another test set to evaluate the model\n",
    "\n",
    "this means the two test datasets below \\\n",
    "are completely unseen to the model we train\n",
    "\"\"\"\n",
    "test_split = 0.2\n",
    "ariana_train, ariana_test = tweets(\"ariana\", test_size=test_split)\n",
    "trump_train, trump_test = tweets(\"trump\", test_size=test_split)\n",
    "\n",
    "y = [1]*len(ariana_train) + [0]*len(trump_train)\n",
    "x = ariana_train + trump_train\n",
    "print(\"Train samples: {}\".format(len(x)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=4310)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eaa5e-140c-4958-b14d-3b919a99266b",
   "metadata": {},
   "source": [
    "### TF-IDF + logistic regression\n",
    "- Vectorize the tweets (e.g. with Count Vectorizer or TF-IDF Vectorizer).\n",
    "- Logistic regression is neat because it spits out whether something is true or not.\n",
    "    - This is exactly what we want in this case, to determine between two types of tweet sources (1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dec3930-b21b-43fb-adb4-bfa6d3e1fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  5]\n",
      " [ 2 14]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# define regression and fit\n",
    "LR = LogisticRegression()\n",
    "LR.fit(vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "# evaluate by confusion matrix\n",
    "y_pred = predict(LR, vectorizer, X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505068b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e5af6a-ba13-436b-8236-60880f15af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heaven sent u\n",
      "Trump: 50.3% / Ariana: 49.7%\n",
      "--------------------------------------------------\n",
      "ari album check table get chance also listen whole album proud\n",
      "Trump: 34.5% / Ariana: 65.5%\n",
      "--------------------------------------------------\n",
      "arianators get position new\n",
      "Trump: 45.8% / Ariana: 54.2%\n",
      "--------------------------------------------------\n",
      "alt physical cover positions\n",
      "Trump: 25.0% / Ariana: 75.0%\n",
      "--------------------------------------------------\n",
      "miss u sending love got\n",
      "Trump: 25.4% / Ariana: 74.6%\n",
      "--------------------------------------------------\n",
      "ya motive\n",
      "Trump: 47.7% / Ariana: 52.3%\n",
      "--------------------------------------------------\n",
      "three days\n",
      "Trump: 41.1% / Ariana: 58.9%\n",
      "--------------------------------------------------\n",
      "florida voters deadline register vote extended tonight register vote\n",
      "Trump: 32.4% / Ariana: 67.6%\n",
      "--------------------------------------------------\n",
      "hello thank u favorite album yet response music made heart incredibly ful\n",
      "Trump: 28.7% / Ariana: 71.3%\n",
      "--------------------------------------------------\n",
      "\n",
      "Trump: 47.7% / Ariana: 52.3%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ariana_prob = predict(LR, vectorizer, ariana_test, all_predictions=True)\n",
    "print_examples(ariana_test, ariana_prob, \"Trump\", \"Ariana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5064f616-39ac-432d-ba69-4dc8297397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president departs new jersey\n",
      "Trump: 69.7% / Ariana: 30.3%\n",
      "--------------------------------------------------\n",
      "take care people fault plague came china\n",
      "Trump: 56.2% / Ariana: 43.8%\n",
      "--------------------------------------------------\n",
      "obamacare replaced much better far cheaper alternative terminated supreme court\n",
      "Trump: 60.2% / Ariana: 39.8%\n",
      "--------------------------------------------------\n",
      "authorized tens millions vaccine doses available month hundreds millions qui\n",
      "Trump: 61.6% / Ariana: 38.4%\n",
      "--------------------------------------------------\n",
      "another million rapid tests support efforts reopen economies quickly possible including te\n",
      "Trump: 61.2% / Ariana: 38.8%\n",
      "--------------------------------------------------\n",
      "pleased announce christopher c miller highly respected director national counterterrorism ce\n",
      "Trump: 53.4% / Ariana: 46.6%\n",
      "--------------------------------------------------\n",
      "getting ready land great state florida see soon\n",
      "Trump: 59.7% / Ariana: 40.3%\n",
      "--------------------------------------------------\n",
      "judge barrett confirmed circuit court bipartisan vote qualifications unsurpassed b\n",
      "Trump: 60.7% / Ariana: 39.3%\n",
      "--------------------------------------------------\n",
      "marched white house understand protect lives black americans americans\n",
      "Trump: 66.5% / Ariana: 33.5%\n",
      "--------------------------------------------------\n",
      "providing better care choice lower cost delivering healthier safer brighter\n",
      "Trump: 60.5% / Ariana: 39.5%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trump_prob = predict(LR, vectorizer, trump_test, all_predictions=True)\n",
    "print_examples(trump_test, trump_prob, \"Trump\", \"Ariana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd37cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "29f1e52c0d8d5e5ede6aaca4be8238d35b46afd62a3b8286547e2768de775769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
