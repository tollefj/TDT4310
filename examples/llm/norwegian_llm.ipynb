{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tollefj/nordavind-7b-instruct-warm\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=\"mps\",  # mps if you're on an apple silicon mac, else \"cuda\" if nvidia-gpu or \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'Du er \"Nordavind\", en hjelpsom assistent.'\n",
    "\n",
    "def make_prompt(inst, res=None):\n",
    "    if not res:\n",
    "        return f\"\"\"<s>{system_prompt} [INST] {inst} [/INST] \\\\n\"\"\"\n",
    "    return f\"\"\"<s>{system_prompt} [INST] {inst} [/INST] \\\\n {res} </s>\"\"\"\n",
    "\n",
    "def postprocess(output, first_sent=False):\n",
    "    output = output.split(\"\\\\n\")[-1].strip()\n",
    "    # ignore hashtags as we often see #no_output\n",
    "    output = output.split(\"#\")[0].strip()\n",
    "    # ignore incomplete sentences\n",
    "    if not output.endswith(\".\"):\n",
    "        output = output.rsplit(\".\", 1)[0] + \".\"\n",
    "    if first_sent:\n",
    "        return output.split(\".\")[0] + \".\"\n",
    "    return output\n",
    "\n",
    "def generate(prompt, tokens=100, first_sent=False, sample=False, temperature=1.0):\n",
    "    prompt = make_prompt(prompt)\n",
    "    output = pipe(\n",
    "        prompt,\n",
    "        max_length=tokens,\n",
    "        do_sample=sample,\n",
    "        temperature=temperature,\n",
    "        no_repeat_ngram_size=3,\n",
    "    )\n",
    "    output = output[0][\"generated_text\"]\n",
    "    output = postprocess(output, first_sent=first_sent)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTNU og Institutt for datateknologi og informatikk (IDI) er to forskjellige organisasjoner. NTNU er Norges største universitet, og består av syv fakulteter og 40 institutter. IDI er imidlertid bare en av de 40 enhetene som utgjør Fakultet for informasjonsteknologi og elektroteknikk.\n"
     ]
    }
   ],
   "source": [
    "generate(\n",
    "    \"Hva er NTNU og IDI?\",\n",
    "    sample=True,\n",
    "    tokens=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of speech tagger er en prosess som brukes til å identifisere ordklasser i en tekst. Stemming/Lemmatizering er en teknikk som brukes for å redusere lengden på ord ved å fjerne suffikser og prefikser. TFIDF er en algoritme som brukes i naturlig språkbehandling for å beregne relevansen til et dokument basert på dets frekvens og invers dokumentfrekvens.  TF er et mål på hvor ofte et ord forekommer i et dokument. IDF er invers av dokumentfrekvensen, som er et tall som indikerer hvor viktig et ord er i et gitt dokument.  Til sammen gir disse tre teknikkene en måte å analysere tekst på og trekke ut relevant informasjon.\n"
     ]
    }
   ],
   "source": [
    "generate(\"Forklar part-of-speech tagging, stemming/lemmatization og TF-IDF\", tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS-tagger er en type språkmodell som brukes til å merke ord i tekst. Den bruker en forhåndsopplært modell for å identifisere ordklasser som substantiv, verb, adjektiv, preposisjoner, etc.\n"
     ]
    }
   ],
   "source": [
    "generate(\"Svart kort på følgende oppgve: 1. Briefly describe your understanding of POS tagging and its possible use-cases in context of text generation applications/language modeling.\", tokens=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
